output_dir: "./models/rubert-tiny2_lora"
overwrite_output_dir: true
num_train_epochs: 5
per_device_train_batch_size: 16
per_device_eval_batch_size: 16
logging_dir: "./logs"
logging_steps: 50
eval_strategy: "epoch"
save_strategy: "epoch"
load_best_model_at_end: true
metric_for_best_model: "weighted_f1"
greater_is_better: true
fp16: true # Will be overridden based on hardware
dataloader_pin_memory: false
report_to: "none"
seed: ${seed}

early_stopping:
  patience: 2

learning_rate: 2.0e-4
weight_decay: 0.01
warmup_ratio: 0.1
